# Analysis of Knowledge Graph Entity Matching with spaCy

## Current Results Analysis

In the current implementation, Test 7 shows a 50% match rate between entities in the Knowledge Graph (KG) and entities detected by spaCy in the narrative. Let's break down what's happening:

1. **KG Entities (4 total)**: 
   - Alice
   - Wonderland
   - White Rabbit
   - Animal

2. **Entities Found by spaCy in Narrative**:
   - Alice (PERSON) - detected multiple times
   - Wonderland (GPE)
   - One sunny afternoon (TIME)
   - The White Rabbit (ORG)

3. **Matched Entities (2 out of 4)**:
   - 'alice' found in narrative
   - 'wonderland' found in narrative

4. **Missing Matches (2 out of 4)**:
   - 'white rabbit' - Not matched because spaCy detected "The White Rabbit" as a single entity
   - 'animal' - Not found because it's not explicitly mentioned as a standalone entity in the narrative

## Technical Limitations and Challenges

1. **Entity Recognition Differences**:
   - spaCy's Named Entity Recognition (NER) is trained to identify specific entity types (PERSON, ORG, GPE, etc.)
   - KG entities are defined by the triplets and don't necessarily align with NER categories
   - Case sensitivity and exact string matching issues (e.g., "White Rabbit" vs "The White Rabbit")

2. **Implicit vs. Explicit Mentions**:
   - The narrative describes the White Rabbit as "being a rather harried animal" but doesn't explicitly use "Animal" as a standalone entity
   - spaCy doesn't recognize "animal" as a named entity in this context

3. **Compound Entity Names**:
   - "White Rabbit" is treated as a single entity in the KG but spaCy detects "The White Rabbit" with the article included

4. **Limited NLP Processing**:
   - The current implementation only uses basic entity extraction
   - No coreference resolution (recognizing that "it" refers to "White Rabbit")
   - No relation extraction between entities

## Approaches to Improve Entity Matching

### 1. Enhanced Entity Matching

```python
# Improved entity matching with partial matching and normalization
def improved_entity_matching(kg_entities, narrative_text, nlp):
    # Process the narrative with spaCy
    doc = nlp(narrative_text)
    
    # Extract named entities from spaCy
    spacy_entities = {ent.text.lower() for ent in doc.ents}
    
    # Add noun chunks as potential entities (helps with compound names)
    noun_chunks = {chunk.text.lower() for chunk in doc.noun_chunks}
    
    # Combine all potential entity mentions
    all_potential_entities = spacy_entities.union(noun_chunks)
    
    # Normalize KG entities (lowercase)
    kg_entities_lower = {ent.lower() for ent in kg_entities}
    
    # Track matches
    matched_entities = set()
    
    # Direct matching
    for kg_ent in kg_entities_lower:
        if kg_ent in all_potential_entities:
            matched_entities.add(kg_ent)
            continue
            
        # Try partial matching for multi-word entities
        for potential_ent in all_potential_entities:
            # Check if KG entity is contained within a longer entity or vice versa
            if kg_ent in potential_ent or potential_ent in kg_ent:
                matched_entities.add(kg_ent)
                break
    
    return matched_entities
```

### 2. Semantic Similarity Matching

```python
# Using word vectors for semantic similarity matching
def semantic_similarity_matching(kg_entities, narrative_text, nlp):
    # Process the narrative with spaCy
    doc = nlp(narrative_text)
    
    # Extract all potential entity mentions (named entities and noun chunks)
    potential_entities = list(doc.ents) + list(doc.noun_chunks)
    
    # Normalize KG entities
    kg_entities_lower = [ent.lower() for ent in kg_entities]
    
    # Track matches with similarity scores
    matches = {}
    
    # Compare each KG entity with each potential entity in the narrative
    for kg_ent in kg_entities_lower:
        kg_ent_doc = nlp(kg_ent)
        
        best_match = None
        best_score = 0.0
        
        for pot_ent in potential_entities:
            # Calculate similarity score
            similarity = kg_ent_doc.similarity(pot_ent)
            
            # Update if this is the best match so far
            if similarity > best_score and similarity > 0.7:  # Threshold
                best_score = similarity
                best_match = pot_ent.text
        
        if best_match:
            matches[kg_ent] = (best_match, best_score)
    
    return matches
```

### 3. Custom Rule-Based Entity Extraction

```python
# Custom rules to extract specific entity types from the narrative
def custom_entity_extraction(narrative_text, entity_types):
    """
    Extract entities of specific types using custom patterns
    
    entity_types: dict mapping entity type to list of keywords/patterns
    """
    extracted_entities = {}
    
    for entity_type, keywords in entity_types.items():
        entities = []
        
        for keyword in keywords:
            # Simple keyword matching (could be enhanced with regex)
            if keyword.lower() in narrative_text.lower():
                entities.append(keyword)
                
        if entities:
            extracted_entities[entity_type] = entities
            
    return extracted_entities

# Example usage
entity_types = {
    "Animal": ["animal", "rabbit", "hare"],
    "Person": ["Alice", "girl"],
    "Location": ["Wonderland", "meadow", "burrow"]
}
```

### 4. Relation Extraction for Triplet Validation

```python
# Extract potential relations between entities in the narrative
def extract_relations(doc):
    relations = []
    
    for sent in doc.sents:
        root = sent.root
        
        # Look for subject-verb-object patterns
        if root.pos_ == "VERB":
            subject = None
            direct_object = None
            
            # Find the subject
            for child in root.children:
                if child.dep_ in ("nsubj", "nsubjpass"):
                    subject = child
                    break
            
            # Find the direct object
            for child in root.children:
                if child.dep_ == "dobj":
                    direct_object = child
                    break
            
            # If we found both subject and object, extract the relation
            if subject and direct_object:
                relations.append({
                    "subject": subject.text,
                    "predicate": root.text,
                    "object": direct_object.text
                })
    
    return relations
```

## Implementation Recommendations

1. **Use a More Advanced spaCy Model**:
   - Upgrade from 'en_core_web_sm' to 'en_core_web_lg' or 'en_core_web_trf' for better entity recognition and word vectors
   - `nlp = spacy.load("en_core_web_lg")`

2. **Implement Multi-Strategy Entity Matching**:
   - Combine direct string matching, partial matching, and semantic similarity
   - Use noun chunks in addition to named entities
   - Consider custom entity extraction for domain-specific entities

3. **Improve Triplet Extraction from LLM Responses**:
   - Enhance the prompt to encourage more explicit entity mentions
   - Consider using structured output formats (JSON) for more reliable parsing

4. **Implement Coreference Resolution**:
   - Use neuralcoref or other coreference resolution libraries to link pronouns to their referents
   - `import neuralcoref; neuralcoref.add_to_pipe(nlp)`

5. **Add Relation Extraction**:
   - Extract subject-verb-object patterns from the narrative
   - Compare these to the KG triplets for validation

6. **Knowledge Graph Enrichment**:
   - Use the narrative to discover new entities and relations not in the original triplets
   - Add these as potential new triplets to the KG

## Example Implementation for Improved Entity Matching

```python
def enhanced_analyze_narrative_with_spacy(narrative_text, triplets_in_kg):
    """Enhanced analysis of narrative with improved entity matching."""
    print("\nAnalyzing narrative with spaCy (enhanced)...")
    log_message("Analyzing narrative with spaCy (enhanced)")
    
    if nlp is None or not narrative_text or not triplets_in_kg:
        return {"status": "skipped", "match_percentage": 0}
    
    # Extract unique entities from KG triplets
    kg_entities = set()
    for s, p, o in triplets_in_kg:
        kg_entities.add(s)
        kg_entities.add(o)
    
    # Process the narrative
    doc = nlp(narrative_text)
    
    # 1. Extract named entities
    named_entities = {ent.text.lower() for ent in doc.ents}
    
    # 2. Extract noun chunks (helps with compound names)
    noun_chunks = {chunk.text.lower() for chunk in doc.noun_chunks}
    
    # 3. Extract individual nouns
    individual_nouns = {token.text.lower() for token in doc if token.pos_ == "NOUN"}
    
    # Combine all potential entity mentions
    all_potential_entities = named_entities.union(noun_chunks).union(individual_nouns)
    
    # Normalize KG entities
    kg_entities_lower = {ent.lower() for ent in kg_entities}
    
    # Match entities using multiple strategies
    matched_entities = set()
    match_details = {}
    
    for kg_ent in kg_entities_lower:
        # Strategy 1: Direct matching
        if kg_ent in all_potential_entities:
            matched_entities.add(kg_ent)
            match_details[kg_ent] = "direct_match"
            continue
        
        # Strategy 2: Partial matching for multi-word entities
        for pot_ent in all_potential_entities:
            # Check if KG entity is contained within a longer entity or vice versa
            if (len(kg_ent.split()) > 1 or len(pot_ent.split()) > 1) and \
               (kg_ent in pot_ent or pot_ent in kg_ent):
                matched_entities.add(kg_ent)
                match_details[kg_ent] = f"partial_match_with_{pot_ent}"
                break
    
    # Calculate match percentage
    match_percentage = (len(matched_entities) / len(kg_entities)) * 100 if kg_entities else 0
    
    # Log results
    print(f"Enhanced SpaCy Analysis Results:")
    print(f"  All potential entities in narrative: {len(all_potential_entities)}")
    print(f"  Entities in KG: {len(kg_entities)}")
    print(f"  KG Entities matched in narrative: {len(matched_entities)}")
    print(f"  Entity Match Percentage: {match_percentage:.2f}%")
    
    for kg_ent in kg_entities_lower:
        status = "✓ MATCHED" if kg_ent in matched_entities else "✗ NOT MATCHED"
        details = match_details.get(kg_ent, "")
        print(f"  {kg_ent}: {status} {details}")
    
    return {
        "status": "completed",
        "match_percentage": match_percentage,
        "kg_entity_count": len(kg_entities),
        "narrative_entity_count": len(all_potential_entities),
        "kg_entities_matched": len(matched_entities),
        "matched_entities": list(matched_entities),
        "match_details": match_details
    }
```

## Conclusion

The current 50% match rate is primarily due to limitations in the entity matching approach. By implementing the suggested improvements, particularly the enhanced entity matching strategies, you can significantly increase the match percentage and extract more value from the narrative text.

The ultimate goal should be to not only validate existing KG triplets but also to discover new knowledge from the narrative that can enrich your knowledge graph. This bidirectional approach (KG → narrative → enhanced KG) creates a virtuous cycle of knowledge enrichment that maximizes the value of both your structured KG data and unstructured narrative text.


# Potential New Triplets Extracted from Narrative

Date: 2025-04-24T11:51:14.390204

The following triplets were automatically extracted from the narrative and could potentially be added to the Knowledge Graph:

* (that, sing, lullabies)
* (this rabbit, wear, a waistcoat)
* (Alice, follow, it)
* (it, dart, a burrow)
* (the girl, trail, a peculiar encounter)
* (that, lead, Alice)

These triplets are provided for review and are not automatically added to the Knowledge Graph.


# Potential New Triplets Extracted from Narrative

Date: 2025-04-24T18:52:07.851757

The following triplets were automatically extracted from the narrative and could potentially be added to the Knowledge Graph:

* (that, sing, lullabies)
* (this rabbit, wear, a waistcoat)
* (Alice, follow, it)
* (it, dart, a burrow)
* (the girl, trail, a peculiar encounter)
* (that, lead, Alice)

These triplets are provided for review and are not automatically added to the Knowledge Graph.


# Enhanced Triplet Extraction Results

Date: 2025-04-24T18:52:08.605780

The following triplets were extracted using enhanced relation extraction techniques:

* (Alice, live_in, the curious land)
* (that, sing, lullabies)
* (this rabbit, wear, a waistcoat)
* (this rabbit, wear_Unlike, any ordinary hare)
* (Alice, follow, it)
* (it, dart, a burrow)
* (the girl, trail, a peculiar encounter)
* (that, lead, Alice)
* (that, lead_into, Wonderland’s enchanted heart)
* (Wonderland, has, Wonderland’s enchanted heart)

These triplets represent potential new knowledge that could be added to the Knowledge Graph.


# Potential New Triplets Extracted from Narrative

Date: 2025-04-24T20:47:12.483524

The following triplets were automatically extracted from the narrative and could potentially be added to the Knowledge Graph:

* (that, sing, lullabies)
* (this rabbit, wear, a waistcoat)
* (Alice, follow, it)
* (it, dart, a burrow)
* (the girl, trail, a peculiar encounter)
* (that, lead, Alice)

These triplets are provided for review and are not automatically added to the Knowledge Graph.


# Enhanced Triplet Extraction Results

Date: 2025-04-24T20:47:13.238495

The following triplets were extracted using enhanced relation extraction techniques:

* (Alice, live_in, the curious land)
* (that, sing, lullabies)
* (she, spot, a White Rabbit)
* (this rabbit, wear, a waistcoat)
* (this rabbit, wear_Unlike, any ordinary hare)
* (Alice, follow, it)
* (it, dart_down, a burrow)
* (The White Rabbit, notice, a peculiar encounter)
* (that, lead, Alice)
* (that, lead_into, Wonderland’s enchanted heart)
* (Wonderland, has, Wonderland’s enchanted heart)

These triplets represent potential new knowledge that could be added to the Knowledge Graph.
